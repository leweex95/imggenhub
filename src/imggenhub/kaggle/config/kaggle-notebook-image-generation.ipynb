{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "815b8b76",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline, StableDiffusionXLInpaintPipeline\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import papermill as pm\n",
        "\n",
        "# -------- SETTINGS ---------\n",
        "MODEL_ID = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "REFINER_MODEL_ID = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
        "# -------- PARAMETERS (can be overridden when running via papermill) ---------\n",
        "PROMPTS = ['A highly detailed photorealistic portrait of a young Russian woman visible from chest upwards, with long flowing hair, professional studio lighting, sharp focus on eyes, cinematic composition, 8K resolution, masterpiece quality, with Russian flag in the background on one side and some famous Russian buildings in afar on the left side. Make sure the flag and the Russian buildings are noticeable.']\n",
        "NEGATIVE_PROMPT = \"blurry, low quality, distorted, watermark, duplicate, multiple identical people, clones, repetition, cartoon, anime, painting, drawing, sketch, low resolution, pixelated, noisy, grainy, artifacts, overexposed, underexposed, bad anatomy, deformed, ugly, disfigured, poorly lit, bad composition\"\n",
        "OUTPUT_DIR = \"output/20251114_124830\"\n",
        "IMG_SIZE = (1080, 1920)  # HD ~16:9 aspect ratio for wide images\n",
        "GUIDANCE = 12.0\n",
        "STEPS = 75\n",
        "REFINER_STEPS = 20  # Additional refinement steps\n",
        "SEED = 42\n",
        "USE_GPU = True\n",
        "USE_REFINER = False\n",
        "PRECISION = \"int8\"\n",
        "# ----------------------------\n",
        "\n",
        "print(\"Parameters:\")\n",
        "print(f\"PROMPTS: {PROMPTS}\")\n",
        "print(f\"NEGATIVE_PROMPT: {NEGATIVE_PROMPT}\")\n",
        "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
        "print(f\"IMG_SIZE: {IMG_SIZE}\")\n",
        "print(f\"GUIDANCE: {GUIDANCE}\")\n",
        "print(f\"STEPS: {STEPS}\")\n",
        "print(f\"REFINER_STEPS: {REFINER_STEPS}\")\n",
        "print(f\"SEED: {SEED}\")\n",
        "print(f\"USE_GPU: {USE_GPU}\")\n",
        "print(f\"USE_REFINER: {USE_REFINER}\")\n",
        "print(f\"PRECISION: {PRECISION}\")\n",
        "print()\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "device = \"cuda\" if USE_GPU and torch.cuda.is_available() else \"cpu\"\n",
        "print(\"GPU available:\", torch.cuda.get_device_name(0) if device==\"cuda\" else \"Running on CPU.\")\n",
        "\n",
        "# Determine torch dtype and model variant based on precision\n",
        "if PRECISION == \"fp32\":\n",
        "    torch_dtype = torch.float32\n",
        "    variant = None\n",
        "elif PRECISION == \"fp16\":\n",
        "    torch_dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
        "    variant = \"fp16\" if device == \"cuda\" else None\n",
        "elif PRECISION in [\"int8\", \"int4\"]:\n",
        "    torch_dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
        "    variant = None  # Quantization will be handled separately\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported precision: {PRECISION}\")\n",
        "\n",
        "# Load base pipeline\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch_dtype,\n",
        "    safety_checker=None,\n",
        "    variant=variant,\n",
        ").to(device)\n",
        "\n",
        "# Load refiner pipeline if enabled\n",
        "if USE_REFINER:\n",
        "    refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "        REFINER_MODEL_ID,\n",
        "        torch_dtype=torch_dtype,\n",
        "        safety_checker=None,\n",
        "        variant=variant,\n",
        "    ).to(device)\n",
        "    print(\"Refiner model loaded for enhanced photorealism\")\n",
        "\n",
        "generator = torch.manual_seed(SEED)\n",
        "\n",
        "# Generate images (1 per prompt)\n",
        "for i, prompt in enumerate(tqdm(PROMPTS, desc=\"Generating\")):\n",
        "    # Base generation\n",
        "    base_image = pipe(\n",
        "        prompt,\n",
        "        negative_prompt=NEGATIVE_PROMPT,\n",
        "        guidance_scale=GUIDANCE,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=generator,\n",
        "        height=IMG_SIZE[0],\n",
        "        width=IMG_SIZE[1],\n",
        "        denoising_end=0.8 if USE_REFINER else None,  # Stop at 80% for refiner\n",
        "    ).images[0]\n",
        "    \n",
        "    # Refinement step for photorealism\n",
        "    if USE_REFINER:\n",
        "        final_image = refiner(\n",
        "            prompt=prompt,\n",
        "            negative_prompt=NEGATIVE_PROMPT,\n",
        "            image=base_image,\n",
        "            guidance_scale=GUIDANCE,\n",
        "            num_inference_steps=REFINER_STEPS,\n",
        "            generator=generator,\n",
        "            denoising_start=0.8,  # Start from 80%\n",
        "        ).images[0]\n",
        "    else:\n",
        "        final_image = base_image\n",
        "    \n",
        "    # Save the image\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"image_{i+1:03d}_{timestamp}.png\"\n",
        "    filepath = os.path.join(OUTPUT_DIR, filename)\n",
        "    final_image.save(filepath)\n",
        "    print(f\"Saved: {filepath}\")\n",
        "\n",
        "print(f\"\\nGeneration complete! Images saved to: {OUTPUT_DIR}\")\n",
        "print(f\"Total images generated: {len(PROMPTS)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
