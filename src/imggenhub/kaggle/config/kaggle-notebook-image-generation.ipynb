{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "815b8b76",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch, os\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import papermill as pm\n",
        "\n",
        "# -------- SETTINGS ---------\n",
        "# MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
        "MODEL_ID = \"stabilityai/stable-diffusion-xl-beta-v2-2\"\n",
        "# -------- PARAMETERS (can be overridden when running via papermill) ---------\n",
        "PROMPTS = ['A photorealistic photograph of a restaurant scene: a single customer ordering food, a waiter presenting the menu, natural lighting, sharp focus, realistic textures, clean background, 16:9 aspect ratio, 4K quality.']\n",
        "NEGATIVE_PROMPT = \"blurry, low quality, distorted, watermark, duplicate, multiple identical people, clones, repetition\"\n",
        "OUTPUT_DIR = \"generated_images\"\n",
        "IMG_SIZE = (1080, 1920)  # HD ~16:9\n",
        "GUIDANCE = 7.5\n",
        "STEPS = 25\n",
        "SEED = 42\n",
        "USE_GPU = True\n",
        "# ----------------------------\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Detect device\n",
        "device = \"cuda\" if USE_GPU and torch.cuda.is_available() else \"cpu\"\n",
        "print(\"GPU available:\", torch.cuda.get_device_name(0) if device==\"cuda\" else \"Running on CPU.\")\n",
        "\n",
        "# Load pipeline\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.float16 if device==\"cuda\" else torch.float32,\n",
        "    safety_checker=None,\n",
        ").to(device)\n",
        "\n",
        "generator = torch.manual_seed(SEED)\n",
        "\n",
        "# Generate images (1 per prompt)\n",
        "for prompt in tqdm(PROMPTS, desc=\"Generating\"):\n",
        "    image = pipe(\n",
        "        prompt,\n",
        "        negative_prompt=NEGATIVE_PROMPT,\n",
        "        guidance_scale=GUIDANCE,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=generator,\n",
        "        height=IMG_SIZE[0],\n",
        "        width=IMG_SIZE[1],\n",
        "    ).images[0]\n",
        "\n",
        "    # Save with timestamp\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"img_{ts}.png\"\n",
        "    save_path = os.path.join(OUTPUT_DIR, filename)\n",
        "    image.save(save_path)\n",
        "    print(f\"Saved image: {save_path}\")\n",
        "\n",
        "# Move to Kaggle Output folder if running on Kaggle\n",
        "if \"KAGGLE_URL_BASE\" in os.environ:\n",
        "    kaggle_output = \"/kaggle/working/output\"\n",
        "    os.makedirs(kaggle_output, exist_ok=True)\n",
        "    for file in os.listdir(OUTPUT_DIR):\n",
        "        src = os.path.join(OUTPUT_DIR, file)\n",
        "        dst = os.path.join(kaggle_output, file)\n",
        "        os.rename(src, dst)\n",
        "    print(f\"Images moved to Kaggle Output folder: {kaggle_output}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}