{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92f81f10",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade accelerate sentencepiece \n",
        "# hf_xet kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "815b8b76",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import gc\n",
        "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# -------- SETTINGS ---------\n",
        "MODEL_ID = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "REFINER_MODEL_ID = \"stabilityai/stable-diffusion-xl-refiner-1.0\"\n",
        "\n",
        "# -------- PARAMETERS (can be overridden when running via papermill) ---------\n",
        "PROMPTS = ['bombed out high rise soviet apartment in kharkiv 2022 ukraine war']\n",
        "NEGATIVE_PROMPT = \"blurry, low quality, distorted, watermark, duplicate, multiple identical people, clones, repetition, cartoon, anime, painting, drawing, sketch, low resolution, pixelated, noisy, grainy, artifacts, overexposed, underexposed, bad anatomy, deformed, ugly, disfigured, poorly lit, bad composition\"\n",
        "OUTPUT_DIR = \"kharkiv_war_apartment_20251120_160600\"\n",
        "IMG_SIZE = (1080, 1920)\n",
        "GUIDANCE = 10.0\n",
        "PRECISION = \"fp16\"\n",
        "STEPS = 75\n",
        "SEED = 42\n",
        "USE_GPU = True\n",
        "USE_REFINER = False\n",
        "REFINER_STEPS = 15\n",
        "REFINER_GUIDANCE = 7.0\n",
        "REFINER_PRECISION = \"fp16\"\n",
        "# ----------------------------\n",
        "\n",
        "def get_vram_gb():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.cuda.memory_allocated() / 1024**3\n",
        "    return 0.0\n",
        "\n",
        "device = \"cuda\" if USE_GPU and torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")\n",
        "if device == \"cuda\":\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "print(f\"\\nVRAM at start: {get_vram_gb():.2f} GB\")\n",
        "print(f\"Prompts: {len(PROMPTS)}\")\n",
        "print(f\"Base precision: {PRECISION}\")\n",
        "if USE_REFINER:\n",
        "    print(f\"Refiner precision: {REFINER_PRECISION}\")\n",
        "print(f\"Steps: {STEPS} (base)\")\n",
        "if USE_REFINER:\n",
        "    print(f\"Refiner steps: {REFINER_STEPS} (refiner)\")\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Determine base model precision\n",
        "if PRECISION == \"fp16\":\n",
        "    base_dtype = torch.float16\n",
        "    base_variant = \"fp16\"\n",
        "elif PRECISION == \"fp32\":\n",
        "    base_dtype = torch.float32\n",
        "    base_variant = None\n",
        "else:\n",
        "    base_dtype = torch.float16\n",
        "    base_variant = \"fp16\"\n",
        "\n",
        "# Determine refiner precision\n",
        "if REFINER_PRECISION == \"fp16\":\n",
        "    refiner_dtype = torch.float16\n",
        "    refiner_variant = \"fp16\"\n",
        "elif REFINER_PRECISION == \"fp32\":\n",
        "    refiner_dtype = torch.float32\n",
        "    refiner_variant = None\n",
        "else:\n",
        "    refiner_dtype = torch.float16\n",
        "    refiner_variant = \"fp16\"\n",
        "\n",
        "generator = torch.manual_seed(SEED)\n",
        "\n",
        "BATCH_SIZE = 1  # tune\n",
        "\n",
        "batched_prompts = [PROMPTS[i:i+BATCH_SIZE] for i in range(0, len(PROMPTS), BATCH_SIZE)]\n",
        "all_base_images = []\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 1 — LOAD BASE ONCE → RUN ALL BATCHES → DELETE\n",
        "# ============================================================\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=base_dtype,\n",
        "    variant=base_variant,\n",
        "    use_safetensors=True,\n",
        "    low_cpu_mem_usage=True,\n",
        ").to(device)\n",
        "\n",
        "for batch in batched_prompts:\n",
        "    out = pipe(\n",
        "        batch,\n",
        "        negative_prompt=[NEGATIVE_PROMPT]*len(batch),\n",
        "        guidance_scale=GUIDANCE,\n",
        "        num_inference_steps=STEPS,\n",
        "        generator=generator,\n",
        "        height=IMG_SIZE[0],\n",
        "        width=IMG_SIZE[1],\n",
        "        denoising_end=0.8 if USE_REFINER else None,\n",
        "    ).images\n",
        "    all_base_images.extend(out)\n",
        "\n",
        "pipe.to(\"cpu\")\n",
        "del pipe\n",
        "torch.cuda.synchronize()\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ============================================================\n",
        "# STAGE 2 — OPTIONAL REFINER: LOAD ONCE → RUN ALL BATCHES → DELETE\n",
        "# ============================================================\n",
        "if USE_REFINER:\n",
        "    refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "        REFINER_MODEL_ID,\n",
        "        torch_dtype=refiner_dtype,\n",
        "        variant=refiner_variant,\n",
        "        use_safetensors=True,\n",
        "        low_cpu_mem_usage=True,\n",
        "    ).to(device)\n",
        "\n",
        "    refined_images = []\n",
        "    idx = 0\n",
        "    for batch in batched_prompts:\n",
        "        imgs = all_base_images[idx: idx+len(batch)]\n",
        "        idx += len(batch)\n",
        "\n",
        "        out = refiner(\n",
        "            batch,\n",
        "            negative_prompt=[NEGATIVE_PROMPT]*len(batch),\n",
        "            image=imgs,\n",
        "            guidance_scale=REFINER_GUIDANCE,\n",
        "            num_inference_steps=REFINER_STEPS,\n",
        "            generator=generator,\n",
        "            denoising_start=0.8,\n",
        "        ).images\n",
        "        refined_images.extend(out)\n",
        "\n",
        "    refiner.to(\"cpu\")\n",
        "    del refiner\n",
        "    torch.cuda.synchronize()\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    final_images = refined_images\n",
        "else:\n",
        "    final_images = all_base_images\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SAVE\n",
        "# ============================================================\n",
        "for i, img in enumerate(final_images):\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    fname = f\"generated_{i+1}_{timestamp}.png\"\n",
        "    img.save(os.path.join(OUTPUT_DIR, fname))\n",
        "    print(f\"Saved: {os.path.join(OUTPUT_DIR, fname)}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"COMPLETE! {len(PROMPTS)} images saved to {OUTPUT_DIR}\")\n",
        "print(f\"Final VRAM: {get_vram_gb():.2f} GB\")\n",
        "print(f\"{'='*60}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
