{"cells":[{"cell_type":"code","execution_count":null,"id":"a569b2cb","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["import gc \n","import os\n","os.environ[\"PYDEVD_DISABLE_FILE_VALIDATION\"] = \"1\""]},{"cell_type":"code","execution_count":null,"id":"834bccd7","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["from diffusers import FluxPipeline\n","from datetime import datetime\n","import torch"]},{"cell_type":"code","execution_count":null,"id":"c05bfc54","metadata":{},"outputs":[],"source":["HF_TOKEN = os.getenv(\"HF_TOKEN\")  # Will be injected from CLI if needed\n","if HF_TOKEN:\n","    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n","    print(\"HF_TOKEN loaded from environment\")\n","else:\n","    print(\"WARNING: HF_TOKEN not set, may fail for gated models\")"]},{"cell_type":"code","execution_count":null,"id":"11b40af4","metadata":{},"outputs":[],"source":["MODEL_ID = \"black-forest-labs/FLUX.1-schnell\"\n","PROMPTS = [\u0027A photorealistic restaurant scene\u0027]\n","OUTPUT_DIR = \".\"\n","IMG_SIZE = (1024, 1024)\n","GUIDANCE = 0.0\n","STEPS = 4\n","SEED = 42\n","PRECISION = \"bf16\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","dtype_map = {\"bf16\": torch.bfloat16, \"fp16\": torch.float16, \"fp32\": torch.float32}\n","torch_dtype = dtype_map.get(PRECISION, torch.bfloat16)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Device: {device}\")\n","\n","def get_vram_gb():\n","    if torch.cuda.is_available():\n","        return torch.cuda.memory_allocated() / 1024**3\n","    return 0.0\n","\n","print(f\"Loading model...\")\n","pipe = FluxPipeline.from_pretrained(MODEL_ID, torch_dtype=torch_dtype)\n","pipe.enable_vae_tiling()\n","pipe.enable_attention_slicing()\n","pipe.set_progress_bar_config(disable=False)\n","pipe.enable_sequential_cpu_offload()\n","\n","# if torch.cuda.is_available():\n","#     pipe.to(\"cuda\", device_map={\"\": \"cuda\"})\n","# else:\n","#     pipe.to(\"cpu\")\n","\n","print(f\"Model loaded (VRAM: {get_vram_gb():.2f} GB)\")\n","\n","for i, prompt in enumerate(PROMPTS):\n","    print(f\"[{i+1}/{len(PROMPTS)}] {prompt}\")\n","    generator = torch.Generator(device=device).manual_seed(SEED + i)\n","    image = pipe(\n","        prompt,\n","        height=IMG_SIZE[0],\n","        width=IMG_SIZE[1],\n","        guidance_scale=GUIDANCE,\n","        num_inference_steps=STEPS,\n","        generator=generator,\n","        max_sequence_length=256,\n","    ).images[0]\n","    filename = f\"flux_{i+1}_{datetime.now().strftime(\u0027%Y%m%d_%H%M%S\u0027)}.png\"\n","    image.save(os.path.join(OUTPUT_DIR, filename))\n","    print(f\"Saved: {filename}\")\n","    if device == \"cuda\":\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","print(f\"Complete! {len(PROMPTS)} images in {OUTPUT_DIR}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["from IPython.display import display, Markdown\n","from PIL import Image\n","import glob\n","import natsort\n","\n","# Collect all generated PNGs\n","image_paths = natsort.natsorted(glob.glob(os.path.join(OUTPUT_DIR, \"generated_*.png\")))\n","\n","print(f\"Displaying {len(image_paths)} generated images with prompts:\")\n","\n","# Make sure PROMPTS order matches generated images\n","for i, path in enumerate(image_paths):\n","    prompt = PROMPTS[i] if i \u003c len(PROMPTS) else \"Unknown prompt\"\n","    display(Markdown(f\"**Prompt {i+1}:** {prompt}\"))\n","    img = Image.open(path)\n","    display(img)\n","    print(\"-\"*50)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0"}},"nbformat":4,"nbformat_minor":5}
